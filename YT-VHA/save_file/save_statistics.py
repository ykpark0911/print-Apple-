import json

def save_statistics_to_file(statistics_dict, save_path):
    with open(save_path, "w", encoding="utf-8") as f:
        json.dump(statistics_dict, f, indent=2, ensure_ascii=False)
    print("✅ 통계 정보 저장 완료:", save_path)


# statistics_dict = {'shorts_distribution': {'total_takeout': 26961, 'total_sohrts_takeout': 1648, 'shorts_percentage': 6.112532917918475}, 'top_liked_channe': [('휴복', 243), ('Sechya', 30), ('침착맨', 18), ("Lim's", 8), ('한본어 하는 고양 이', 8), ('달이쌤', 7), ('DAZBEE official', 7), ('코딩애플', 6), ('Mrs. GREEN APPLE', 6), ('짤컷', 5)], 'top_channel': {'hours': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], 'counts': [1263, 402, 62, 0, 0, 0, 103, 710, 1405, 1064, 1382, 822, 823, 907, 898, 1497, 1745, 1868, 2072, 2046, 2123, 1704, 2122, 1943]}, 'hour_distribution': {'day_dates': ['2025-02-27', '2025-02-28', '2025-03-01', '2025-03-02', '2025-03-03', '2025-03-04', '2025-03-05', '2025-03-06', '2025-03-07', '2025-03-08', '2025-03-09', '2025-03-10', '2025-03-11', '2025-03-12', '2025-03-13', '2025-03-14', '2025-03-15', '2025-03-16', '2025-03-17', '2025-03-18', '2025-03-19', '2025-03-20', '2025-03-21', '2025-03-22', '2025-03-23', '2025-03-24', '2025-03-25', '2025-03-26', '2025-03-27', '2025-03-28', '2025-03-29', '2025-03-30', '2025-03-31', '2025-04-01', '2025-04-02', '2025-04-03', '2025-04-04', '2025-04-05', '2025-04-06', '2025-04-07', '2025-04-08', '2025-04-09', '2025-04-10', '2025-04-11', '2025-04-12', '2025-04-13', '2025-04-14', '2025-04-15', '2025-04-16', '2025-04-17', '2025-04-18', '2025-04-19', '2025-04-20', '2025-04-21', '2025-04-22', '2025-04-23', '2025-04-24', '2025-04-25', '2025-04-26', '2025-04-27', '2025-04-28', '2025-04-29', '2025-04-30', '2025-05-01', '2025-05-02', '2025-05-03', '2025-05-04', '2025-05-05', '2025-05-06', '2025-05-07', '2025-05-08', '2025-05-09', '2025-05-10', '2025-05-11', '2025-05-12', '2025-05-13', '2025-05-14', '2025-05-15', '2025-05-16', '2025-05-17', '2025-05-18', '2025-05-19', '2025-05-20', '2025-05-21', '2025-05-22'], '_counts': [218, 635, 490, 487, 384, 97, 251, 93, 366, 230, 320, 612, 131, 269, 153, 263, 328, 471, 153, 388, 345, 82, 266, 150, 101, 211, 258, 381, 81, 385, 267, 152, 197, 105, 459, 118, 429, 279, 153, 290, 266, 513, 120, 481, 549, 452, 355, 498, 301, 404, 392, 618, 795, 358, 434, 856, 268, 299, 684, 785, 303, 75, 121, 40, 220, 268, 95, 187, 338, 506, 300, 407, 227, 378, 259, 185, 605, 146, 100, 370, 321, 429, 202, 402, 1]}, 'day_date_distribution': {'average_week_dates': ['2025-02-24 ~ 03-02', '2025-03-03 ~ 03-09', '2025-03-10 ~ 03-16', '2025-03-17 ~ 03-23', '2025-03-24 ~ 03-30', '2025-03-31 ~ 04-06', '2025-04-07 ~ 04-13', '2025-04-14 ~ 04-20', '2025-04-21 ~ 04-27', '2025-04-28 ~ 05-04', '2025-05-05 ~ 05-11', '2025-05-12 ~ 05-18', '2025-05-19 ~ 05-25'], '_counts': [457, 248, 318, 212, 247, 248, 381, 480, 526, 160, 334, 283, 258]}, 'week_date_distribution': {'month_dates': ['2025-02', '2025-03', '2025-04', '2025-05'], '_counts': [853, 8362, 11760, 5986]}, 'month_date_distribution': {'average_week_dates': ['2025-02-24 ~ 03-02', '2025-03-03 ~ 03-09', '2025-03-10 ~ 03-16', '2025-03-17 ~ 03-23', '2025-03-24 ~ 03-30', '2025-03-31 ~ 04-06', '2025-04-07 ~ 04-13', '2025-04-14 ~ 04-20', '2025-04-21 ~ 04-27', '2025-04-28 ~ 05-04', '2025-05-05 ~ 05-11', '2025-05-12 ~ 05-18', '2025-05-19 ~ 05-25'], '_counts': [457, 248, 318, 212, 247, 248, 381, 480, 526, 160, 334, 283, 258]}, 'average_week_date_distribution': {'average_month_dates': ['2025-02', '2025-03', '2025-04', '2025-05'], '_counts': [426, 269, 392, 272]}, 'average_month_date_distribution': {'weekDay_dates': ['Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday'], '_counts': [4243, 3738, 4460, 4510, 2024, 2977, 5009]}, 'weekDay_date_distribution': {'categories': ['Music', 'Gaming', 'People & Blogs', 'Entertainment', 'Science & Technology', 'Education', 'Film & Animation', 'News & Politics', 'Howto & Style', 'Comedy', 'Autos & Vehicles'], 'counts': [1217, 315, 33, 25, 22, 10, 9, 7, 5, 4, 1]}, 'category_distribution': {'categories': ['Music', 'Gaming', 'People & Blogs', 'Entertainment', 'Science & Technology', 'Education', 'Film & Animation', 'News & Politics', 'Howto & Style', 'Comedy', 'Autos & Vehicles'], 'counts': [1217, 315, 33, 25, 22, 10, 9, 7, 5, 4, 1]}}
# save_path = "C:\\Users\\user\\Desktop\\통계\\my_statistics.json"

# save_statistics_to_file(statistics_dict, save_path)